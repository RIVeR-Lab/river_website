---
# Documentation: https://wowchemy.com/docs/managing-content/

title: End-to-end grasping policies for human-in-the-loop robots via deep reinforcement
  learning
subtitle: ''
summary: ''
authors:
- Mohammadreza Sharif
- Deniz Erdogmus
- Christopher Amato
- Taşkın Padır
tags:
- Electromyography
- Grasping
- Monte Carlo methods
- Reinforcement learning
- Robustness
- Stochastic processes
- Training
categories: []
date: '2021-05-01'
lastmod: 2022-06-24T16:44:33-04:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-06-24T20:44:33.147372Z'
publication_types:
- '1'
abstract: State-of-the-art human-in-the-loop robot grasping is hugely suffered by
  Electromyography (EMG) inference robustness issues. As a workaround, researchers
  have been looking into integrating EMG with other signals, often in an ad hoc manner.
  In this paper, we are presenting a method for end-to-end training of a policy for
  human-in-the-loop robot grasping on real reaching trajectories. For this purpose
  we use Reinforcement Learning (RL) and Imitation Learning (IL) in DEXTRON (DEXTerity
  enviRONment), a stochastic simulation environment with real human trajectories that
  are augmented and selected using a Monte Carlo (MC) simulation method. We also offer
  a success model which once trained on the expert policy data and the RL policy roll-out
  transitions, can provide transparency to how the deep policy works and when it is
  probably going to fail.
publication: '*2021 IEEE International Conference on Robotics and Automation (ICRA)*'
doi: 10.1109/ICRA48506.2021.9561937
---
